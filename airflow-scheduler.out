[2m2025-10-02T18:01:30.919905Z[0m [[32m[1minfo     [0m] [1mStarting the scheduler        [0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:1018[0m
[2m2025-10-02T18:01:30.927566Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2240[0m
Dag run  in running state
Dag information Queued at: 2025-10-02 18:01:31.014171+00:00 version: 1
[2m2025-10-02T18:01:31.198592Z[0m [[32m[1minfo     [0m] [1m1 tasks up for execution:
	<TaskInstance: expense_tracker_pipeline.fetch_and_save_emails scheduled__2025-10-02T00:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:419[0m
[2m2025-10-02T18:01:31.198895Z[0m [[32m[1minfo     [0m] [1mDAG expense_tracker_pipeline has 0/16 running and queued tasks[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:491[0m
[2m2025-10-02T18:01:31.199818Z[0m [[32m[1minfo     [0m] [1mSetting the following tasks to queued state:
	<TaskInstance: expense_tracker_pipeline.fetch_and_save_emails scheduled__2025-10-02T00:00:00+00:00 [scheduled]>[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:630[0m
[2m2025-10-02T18:01:31.202382Z[0m [[32m[1minfo     [0m] [1mTrying to enqueue tasks: [<TaskInstance: expense_tracker_pipeline.fetch_and_save_emails scheduled__2025-10-02T00:00:00+00:00 [scheduled]>] for executor: LocalExecutor(parallelism=32)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:715[0m
[2m2025-10-02T18:01:31.333872Z[0m [[32m[1minfo     [0m] [1mSecrets backends loaded for worker[0m [[0m[1m[34msupervisor[0m][0m [36mbackend_classes[0m=[35m['EnvironmentVariablesBackend'][0m [36mcount[0m=[35m1[0m [36mloc[0m=[35msupervisor.py:1870[0m
[2m2025-10-02T18:01:31.360756Z[0m [[33m[1mwarning  [0m] [1mStarting call to 'airflow.sdk.api.client.Client.request', this is the 1st time calling it.[0m [[0m[1m[34mairflow.sdk.api.client[0m][0m [36mloc[0m=[35mbefore.py:42[0m
[2m2025-10-02T18:01:32.363013Z[0m [[33m[1mwarning  [0m] [1mStarting call to 'airflow.sdk.api.client.Client.request', this is the 2nd time calling it.[0m [[0m[1m[34mairflow.sdk.api.client[0m][0m [36mloc[0m=[35mbefore.py:42[0m
[2m2025-10-02T18:01:34.088345Z[0m [[33m[1mwarning  [0m] [1mStarting call to 'airflow.sdk.api.client.Client.request', this is the 3rd time calling it.[0m [[0m[1m[34mairflow.sdk.api.client[0m][0m [36mloc[0m=[35mbefore.py:42[0m
[2m2025-10-02T18:01:37.869615Z[0m [[33m[1mwarning  [0m] [1mStarting call to 'airflow.sdk.api.client.Client.request', this is the 4th time calling it.[0m [[0m[1m[34mairflow.sdk.api.client[0m][0m [36mloc[0m=[35mbefore.py:42[0m
[2m2025-10-02T18:01:45.119841Z[0m [[32m[1minfo     [0m] [1mProcess exited                [0m [[0m[1m[34msupervisor[0m][0m [36mexit_code[0m=[35m<Negsignal.SIGKILL: -9>[0m [36mloc[0m=[35msupervisor.py:709[0m [36mpid[0m=[35m3213065[0m [36msignal_sent[0m=[35mSIGKILL[0m
[2m2025-10-02T18:01:45.589739Z[0m [[32m[1minfo     [0m] [1mReceived executor event with state failed for task instance TaskInstanceKey(dag_id='expense_tracker_pipeline', task_id='fetch_and_save_emails', run_id='scheduled__2025-10-02T00:00:00+00:00', try_number=1, map_index=-1)[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:793[0m
[2m2025-10-02T18:01:45.656863Z[0m [[32m[1minfo     [0m] [1mTaskInstance Finished: dag_id=expense_tracker_pipeline, task_id=fetch_and_save_emails, run_id=scheduled__2025-10-02T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=LocalExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-10-02 18:01:31.200445+00:00, scheduled_dttm=2025-10-02 18:01:31.162597+00:00,queued_by_job_id=7, pid=None[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:838[0m
[2m2025-10-02T18:01:45.661386Z[0m [[31m[1merror    [0m] [1mExecutor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: expense_tracker_pipeline.fetch_and_save_emails scheduled__2025-10-02T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally[0m [[0m[1m[34mairflow.task[0m][0m [36mloc[0m=[35mtaskinstance.py:1505[0m
Task instance in failure state
Task instance's state was changed through the API.
Task operator:PythonOperator
Failure caused by Executor LocalExecutor(parallelism=32) reported that the task instance <TaskInstance: expense_tracker_pipeline.fetch_and_save_emails scheduled__2025-10-02T00:00:00+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2m2025-10-02T18:01:47.183013Z[0m [[32m[1minfo     [0m] [1mMarking run <DagRun expense_tracker_pipeline @ 2025-10-02 00:00:00+00:00: scheduled__2025-10-02T00:00:00+00:00, state:running, queued_at: 2025-10-02 18:01:31.014171+00:00. run_type: scheduled> failed[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1171[0m
Dag run  in failure state
Dag information:expense_tracker_pipeline Run id: scheduled__2025-10-02T00:00:00+00:00 Run type: scheduled
Failed with message: task_failure
[2m2025-10-02T18:01:47.184348Z[0m [[32m[1minfo     [0m] [1mDagRun Finished: dag_id=expense_tracker_pipeline, logical_date=2025-10-02 00:00:00+00:00, run_id=scheduled__2025-10-02T00:00:00+00:00, run_start_date=2025-10-02 18:01:31.086530+00:00, run_end_date=2025-10-02 18:01:47.183622+00:00, run_duration=16.097092, state=failed, run_type=scheduled, data_interval_start=2025-10-02 00:00:00+00:00, data_interval_end=2025-10-02 00:00:00+00:00,[0m [[0m[1m[34mairflow.models.dagrun.DagRun[0m][0m [36mloc[0m=[35mdagrun.py:1274[0m
[2m2025-10-02T18:06:31.146967Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2240[0m
[2m2025-10-02T18:11:31.434281Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2240[0m
[2m2025-10-02T18:16:31.527065Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2240[0m
[2m2025-10-02T18:22:45.099539Z[0m [[32m[1minfo     [0m] [1mHeartbeat recovered after 103.89 seconds[0m [[0m[1m[34mairflow.jobs.job.Job[0m][0m [36mloc[0m=[35mjob.py:253[0m
[2m2025-10-02T18:23:12.268372Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2240[0m
[2m2025-10-02T18:28:12.308025Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2240[0m
[2m2025-10-02T18:33:11.650431Z[0m [[32m[1minfo     [0m] [1mDAG bundles loaded: dags-folder, example_dags[0m [[0m[1m[34mairflow.dag_processing.bundles.manager.DagBundlesManager[0m][0m [36mloc[0m=[35mmanager.py:179[0m
[2m2025-10-02T18:33:12.366782Z[0m [[32m[1minfo     [0m] [1mAdopting or resetting orphaned tasks for active dag runs[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:2240[0m
[2m2025-10-02T18:34:37.276952Z[0m [[32m[1minfo     [0m] [1mExiting gracefully upon receiving signal 15[0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:256[0m
[2m2025-10-02T18:34:37.277222Z[0m [[32m[1minfo     [0m] [1mShutting down LocalExecutor; waiting for running tasks to finish.  Signal again if you don't want to wait.[0m [[0m[1m[34mairflow.executors.local_executor.LocalExecutor[0m][0m [36mloc[0m=[35mlocal_executor.py:226[0m
[2m2025-10-02T18:34:37.349635Z[0m [[32m[1minfo     [0m] [1mExited execute loop           [0m [[0m[1m[34mairflow.jobs.scheduler_job_runner.SchedulerJobRunner[0m][0m [36mloc[0m=[35mscheduler_job_runner.py:1058[0m
